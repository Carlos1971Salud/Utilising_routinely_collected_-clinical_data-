{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1695741583206
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.random import seed\n",
        "seed(2)\n",
        "\n",
        "df = pd.read_pickle(r'./combined_data_feb2023.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1695741583517
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "features = ['id','Ward Glucose', 'Haemoglobin',\n",
        "       'Mean cell volume, blood', 'White blood cell count, blood',\n",
        "       'Haematocrit', 'Platelets', 'Urea level, blood', 'Creatinine', 'Sodium',\n",
        "       'Potassium', 'Lymphocytes', 'Neutrophils', 'C-Reactive Protein',\n",
        "       'Eosinophils', 'Alkaline Phosphatase', 'Albumin',\n",
        "       'Alanine Transaminase', 'Bilirubin', 'Total Protein',\n",
        "       'Fibrinogen (clauss)', 'Glucose POCT Strip Blood', 'Ferritin',\n",
        "       'D-Dimer', 'Ward Lactate', 'age', 'sex', 'SARS CoV-2 RNA','pathogenic']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1695741585635
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Train'\n",
              "pathogenic\n",
              "0.0    0.761944\n",
              "1.0    0.238056\n",
              "Name: proportion, dtype: float64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "13354\n",
              "'Val'\n",
              "pathogenic\n",
              "0.0    0.885361\n",
              "1.0    0.114639\n",
              "Name: proportion, dtype: float64\n",
              "1858\n",
              "'Test'\n",
              "pathogenic\n",
              "0.0    0.915928\n",
              "1.0    0.084072\n",
              "Name: proportion, dtype: float64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "5638"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Manual split of training, validation and test set, and displays of their properties\n",
        "\n",
        "start_date = '2014-1-1'\n",
        "train_date = '2020-12-1'\n",
        "val_date = '2021-03-1'\n",
        "\n",
        "train = df[(df['date_culture']>=start_date)&(df['date_culture']<train_date)]\n",
        "\n",
        "val = df[(df['date_culture']>=train_date)&(df['date_culture']<val_date)]\n",
        "\n",
        "test = df[df['date_culture']>=val_date]\n",
        "\n",
        "display('Train')\n",
        "display(train['pathogenic'].value_counts(normalize=True))\n",
        "display(len(train.groupby(['id','date_culture'])))\n",
        "\n",
        "display('Val')\n",
        "display(val['pathogenic'].value_counts(normalize=True))\n",
        "display(len(val.groupby(['id','date_culture'])))\n",
        "\n",
        "display('Test')\n",
        "display(test['pathogenic'].value_counts(normalize=True))\n",
        "display(len(test.groupby(['id','date_culture'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1695741585986
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "train_limited = train[features]\n",
        "val_limited = val[features]\n",
        "test_limited = test[features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1695741586241
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Functions to feature engineer for baseline\n",
        "\n",
        "def aggregate(df):\n",
        "    summarise = df.groupby('id').agg({\n",
        "                                   \n",
        "                                        'Ward Lactate':['min','mean','max'], \n",
        "                                        'Ward Glucose':['min','mean','max'], \n",
        "                                        'Haemoglobin':['min','mean','max'], \n",
        "                                        'Mean cell volume, blood':['min','mean','max'], \n",
        "                                        'White blood cell count, blood':['min','mean','max'], \n",
        "                                        'Haematocrit':['min','mean','max'], \n",
        "                                        'Platelets':['min','mean','max'], \n",
        "                                        'Urea level, blood':['min','mean','max'], \n",
        "                                        'Creatinine':['min','mean','max'], \n",
        "                                        'Sodium':['min','mean','max'], \n",
        "                                        'Potassium':['min','mean','max'], \n",
        "                                        'Lymphocytes':['min','mean','max'], \n",
        "                                        'Neutrophils':['min','mean','max'], \n",
        "                                        'C-Reactive Protein':['min','mean','max'], \n",
        "                                        'Eosinophils':['min','mean','max'], \n",
        "                                        'Alkaline Phosphatase':['min','mean','max'], \n",
        "                                        'Albumin':['min','mean','max'], \n",
        "                                        'Alanine Transaminase':['min','mean','max'], \n",
        "                                        'Bilirubin':['min','mean','max'], \n",
        "                                        'Total Protein':['min','mean','max'], \n",
        "                                        'Fibrinogen (clauss)':['min','mean','max'], \n",
        "                                        'Glucose POCT Strip Blood':['min','mean','max'],  \n",
        "                                        'Ferritin':['min','mean','max'], \n",
        "                                        'D-Dimer':['min','mean','max'], \n",
        "                                        'sex':'first',\n",
        "                                        'age':'first',\n",
        "                                        'pathogenic':'first'})\n",
        "\n",
        "\n",
        "    return summarise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1695741586571
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def aggregate_mean(df):\n",
        "    summarise = df.groupby('id').agg({\n",
        "                                   \n",
        "                                        'Ward Lactate':'mean', \n",
        "                                        'Ward Glucose':'mean', \n",
        "                                        'Haemoglobin':'mean', \n",
        "                                        'Mean cell volume, blood':'mean', \n",
        "                                        'White blood cell count, blood':'mean', \n",
        "                                        'Haematocrit':'mean', \n",
        "                                        'Platelets':'mean', \n",
        "                                        'Urea level, blood':'mean', \n",
        "                                        'Creatinine':'mean', \n",
        "                                        'Sodium':'mean', \n",
        "                                        'Potassium':'mean', \n",
        "                                        'Lymphocytes':'mean', \n",
        "                                        'Neutrophils':'mean', \n",
        "                                        'C-Reactive Protein':'mean', \n",
        "                                        'Eosinophils':'mean', \n",
        "                                        'Alkaline Phosphatase':'mean', \n",
        "                                        'Albumin':'mean', \n",
        "                                        'Alanine Transaminase':'mean', \n",
        "                                        'Bilirubin':'mean', \n",
        "                                        'Total Protein':'mean', \n",
        "                                        'Fibrinogen (clauss)':'mean', \n",
        "                                        'Glucose POCT Strip Blood':'mean',  \n",
        "                                        'Ferritin':'mean', \n",
        "                                        'D-Dimer':'mean', \n",
        "                                        'sex':'first',\n",
        "                                        'age':'first',\n",
        "                                        'pathogenic':'first'})\n",
        "\n",
        "\n",
        "    return summarise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1695741586892
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def aggregate_last(df):\n",
        "    summarise = df.groupby('id').agg({\n",
        "                                   \n",
        "                                        'Ward Lactate':'last', \n",
        "                                        'Ward Glucose':'last', \n",
        "                                        'Haemoglobin':'last', \n",
        "                                        'Mean cell volume, blood':'last', \n",
        "                                        'White blood cell count, blood':'last', \n",
        "                                        'Haematocrit':'last', \n",
        "                                        'Platelets':'last', \n",
        "                                        'Urea level, blood':'last', \n",
        "                                        'Creatinine':'last', \n",
        "                                        'Sodium':'last', \n",
        "                                        'Potassium':'last', \n",
        "                                        'Lymphocytes':'last', \n",
        "                                        'Neutrophils':'last', \n",
        "                                        'C-Reactive Protein':'last', \n",
        "                                        'Eosinophils':'last', \n",
        "                                        'Alkaline Phosphatase':'last', \n",
        "                                        'Albumin':'last', \n",
        "                                        'Alanine Transaminase':'last', \n",
        "                                        'Bilirubin':'last', \n",
        "                                        'Total Protein':'last', \n",
        "                                        'Fibrinogen (clauss)':'last', \n",
        "                                        'Glucose POCT Strip Blood':'last',  \n",
        "                                        'Ferritin':'last', \n",
        "                                        'D-Dimer':'last', \n",
        "                                        'sex':'first',\n",
        "                                        'age':'first',\n",
        "                                        'pathogenic':'first'})\n",
        "\n",
        "\n",
        "    return summarise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1695741587217
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Three different approaches \n",
        "# i) Summarised approach using (min mean max)\n",
        "# ii) Mean only\n",
        "# iii) Last value (on the day of blood culture acquisition)\n",
        "\n",
        "#Summarised\n",
        "train_aggregated = aggregate(train_limited)\n",
        "val_aggregated = aggregate(val_limited)\n",
        "test_aggregated = aggregate(test_limited)\n",
        "\n",
        "#Mean only\n",
        "train_aggregated_mean = aggregate_mean(train_limited)\n",
        "val_aggregated_mean = aggregate_mean(val_limited)\n",
        "test_aggregated_mean = aggregate_mean(test_limited)\n",
        "\n",
        "#Most recent value\n",
        "train_aggregated_last = aggregate_last(train_limited)\n",
        "val_aggregated_last = aggregate_last(val_limited)\n",
        "test_aggregated_last = aggregate_last(test_limited)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1695741587541
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "train_combined = pd.concat([train_aggregated,val_aggregated],axis=0)\n",
        "train_combined_mean = pd.concat([train_aggregated_mean,val_aggregated_mean],axis=0)\n",
        "train_combined_last = pd.concat([train_aggregated_last,val_aggregated_last],axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1695741587855
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "train_combined.columns = [\"_\".join(pair) for pair in train_combined.columns]\n",
        "test_aggregated.columns = [\"_\".join(pair) for pair in test_aggregated.columns]\n",
        "train_combined = train_combined.reset_index()\n",
        "train_combined_mean = train_combined_mean.reset_index()\n",
        "train_combined_last = train_combined_last.reset_index()\n",
        "\n",
        "test_aggregated = test_aggregated.reset_index()\n",
        "test_aggregated_mean = test_aggregated_mean.reset_index()\n",
        "test_aggregated_last = test_aggregated_last.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1695741588166
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15212\n",
              "5638"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(train_combined['id'].nunique())\n",
        "display(test_aggregated['id'].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1695741590693
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Median imputation fitted on train and applied to test\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "si = SimpleImputer(strategy='median')\n",
        "\n",
        "\n",
        "train_imputed = pd.DataFrame(si.fit_transform(train_combined),columns = si.get_feature_names_out())\n",
        "test_imputed = pd.DataFrame(si.transform(test_aggregated),columns = si.get_feature_names_out())\n",
        "\n",
        "train_combined_mean_imputed = pd.DataFrame(si.fit_transform(train_combined_mean),columns = si.get_feature_names_out())\n",
        "test_imputed_mean = pd.DataFrame(si.transform(test_aggregated_mean),columns = si.get_feature_names_out())\n",
        "\n",
        "train_combined_last_imputed = pd.DataFrame(si.fit_transform(train_combined_last),columns = si.get_feature_names_out())\n",
        "test_imputed_last = pd.DataFrame(si.transform(test_aggregated_last),columns = si.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1695741590918
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(solver='lbfgs')\n",
        "\n",
        "data = train_imputed.iloc[:,2:]\n",
        "test = test_imputed.iloc[:,2:]\n",
        "\n",
        "X_train = data.iloc[:,:-1]\n",
        "y_train = data.iloc[:,-1]\n",
        "X_test = test.iloc[:,:-1]\n",
        "y_test = test.iloc[:,-1]\n",
        "\n",
        "data_mean = train_combined_mean_imputed.iloc[:,2:]\n",
        "test_mean = test_imputed_mean.iloc[:,2:]\n",
        "\n",
        "X_train_mean = data_mean.iloc[:,:-1]\n",
        "y_train_mean = data_mean.iloc[:,-1]\n",
        "X_test_mean = test_mean.iloc[:,:-1]\n",
        "y_test_mean = test_mean.iloc[:,-1]\n",
        "\n",
        "data_last = train_combined_last_imputed.iloc[:,2:]\n",
        "test_last = test_imputed_last.iloc[:,2:]\n",
        "\n",
        "X_train_last = data_last.iloc[:,:-1]\n",
        "y_train_last = data_last.iloc[:,-1]\n",
        "X_test_last = test_last.iloc[:,:-1]\n",
        "y_test_last = test_last.iloc[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1695741591230
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "model_base = lr.fit(X_train,y_train)\n",
        "predictions = model_base.predict_proba(X_test)[:,1]\n",
        "\n",
        "model_mean = lr.fit(X_train_mean,y_train_mean)\n",
        "predictions_mean = model_mean.predict_proba(X_test_mean)[:,1]\n",
        "\n",
        "model_last = lr.fit(X_train_last,y_train_last)\n",
        "predictions_last = model_last.predict_proba(X_test_last)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1695741591633
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from functions.tools import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1695741593422
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summarised values\n",
            "Best Threshold=0.200951\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      0.95      0.96      5164\n",
            "         1.0       0.51      0.59      0.55       474\n",
            "\n",
            "    accuracy                           0.92      5638\n",
            "   macro avg       0.74      0.77      0.75      5638\n",
            "weighted avg       0.92      0.92      0.92      5638\n",
            "\n",
            "Specificity 0.9486831913245546\n",
            "Sensitivity 0.5864978902953587\n",
            "ROC score 0.7346515310474659\n",
            "AP 0.47143389720507356\n",
            "PPV 0.5119705340699816\n",
            "NPV 0.9615309126594701\n",
            "BS 0.06505960806079497\n",
            "AUPRC 0.47143389720507356\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print('Summarised values')\n",
        "display(metrics(predictions,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1695741594428
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean only\n",
            "Best Threshold=0.277253\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      0.97      0.96      5164\n",
            "         1.0       0.59      0.51      0.55       474\n",
            "\n",
            "    accuracy                           0.93      5638\n",
            "   macro avg       0.77      0.74      0.75      5638\n",
            "weighted avg       0.92      0.93      0.93      5638\n",
            "\n",
            "Specificity 0.9680480247869868\n",
            "Sensitivity 0.5063291139240507\n",
            "ROC score 0.7227981285563475\n",
            "AP 0.4493867220531532\n",
            "PPV 0.5925925925925926\n",
            "NPV 0.9552837760366902\n",
            "BS 0.06883521859099855\n",
            "AUPRC 0.4493867220531532\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print('Mean only')\n",
        "display(metrics(predictions_mean, y_test_mean))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1695741594816
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Last values\n",
            "Best Threshold=0.238938\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      0.96      0.96      5164\n",
            "         1.0       0.54      0.58      0.56       474\n",
            "\n",
            "    accuracy                           0.92      5638\n",
            "   macro avg       0.75      0.77      0.76      5638\n",
            "weighted avg       0.93      0.92      0.92      5638\n",
            "\n",
            "Specificity 0.9552672347017815\n",
            "Sensitivity 0.5759493670886076\n",
            "ROC score 0.7457323829040388\n",
            "AP 0.4765332724345627\n",
            "PPV 0.5416666666666666\n",
            "NPV 0.960849240358395\n",
            "BS 0.06614090718321455\n",
            "AUPRC 0.4765332724345627\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print('Last values')\n",
        "display(metrics(predictions_last,y_test_last))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1695741595520
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# 5-fold cross validation of scores\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "score = cross_val_score(model_base, X_train, y_train, cv=5, scoring='roc_auc')\n",
        "score_mean = cross_val_score(model_mean, X_train_mean, y_train_mean, cv=5, scoring='roc_auc')\n",
        "score_last = cross_val_score(model_last, X_train_last, y_train_last, cv=5, scoring='roc_auc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1695741796940
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUROC scores from 5-fold CV\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.47143389720507356\n",
              "array([0.73028727, 0.8364782 , 0.8288315 , 0.68942633, 0.63515884])\n",
              "array([0.75127527, 0.85330024, 0.8178463 , 0.68467399, 0.63850674])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.47143389720507356 0.47143389720507356 0.47143389720507356\n",
            "0.7302872742587014 0.6894263260610236 0.8288315015298304\n",
            "0.7512752654570647 0.6846739938806783 0.8178462957139792\n"
          ]
        }
      ],
      "source": [
        "print('AUROC scores from 5-fold CV')\n",
        "display(score)\n",
        "display(score_mean)\n",
        "display(score_last)\n",
        "\n",
        "# Scores with inter-quartile ranges\n",
        "\n",
        "print(np.median(score), np.quantile(score,0.25), np.quantile(score,0.75))\n",
        "\n",
        "print(np.median(score_mean),np.quantile(score_mean,0.25),np.quantile(score_mean,0.75))\n",
        "\n",
        "print(np.median(score_last),np.quantile(score_last,0.25),np.quantile(score_last,0.75))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1695741804488
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# 5-fold cross validation of scores\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "score = cross_val_score(model_base, X_train, y_train, cv=5, scoring='average_precision')\n",
        "score_mean = cross_val_score(model_mean, X_train_mean, y_train_mean, cv=5, scoring='average_precision')\n",
        "score_last = cross_val_score(model_last, X_train_last, y_train_last, cv=5, scoring='average_precision')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1695741812047
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AURPC scores from 5-fold CV\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([0.55048453, 0.84547948, 0.85033946, 0.45342842, 0.4358811 ])\n",
              "array([0.54432863, 0.77945724, 0.75861822, 0.4284046 , 0.39496819])\n",
              "array([0.57656793, 0.8131919 , 0.77134434, 0.45680136, 0.43487268])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5504845340692617 0.45342842164994235 0.8454794787696785\n",
            "0.5443286298770807 0.4284045975883137 0.7586182188075594\n",
            "0.5765679343030642 0.4568013634175667 0.7713443419293886\n"
          ]
        }
      ],
      "source": [
        "#AUPRC scores\n",
        "\n",
        "print('AURPC scores from 5-fold CV')\n",
        "display(score)\n",
        "display(score_mean)\n",
        "display(score_last)\n",
        "\n",
        "# Scores with inter-quartile ranges\n",
        "\n",
        "print(np.median(score), np.quantile(score,0.25), np.quantile(score,0.75))\n",
        "print(np.median(score_mean),np.quantile(score_mean,0.25),np.quantile(score_mean,0.75))\n",
        "print(np.median(score_last),np.quantile(score_last,0.25),np.quantile(score_last,0.75))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1695741621784
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "last_value\n",
            "auroc\n",
            "0.75 ( 0.71 - 0.78 )\n",
            "auprc\n",
            "0.48 ( 0.43 - 0.53 )\n",
            "\n",
            "mean_value\n",
            "auroc\n",
            "0.72 ( 0.69 - 0.76 )\n",
            "auprc\n",
            "0.45 ( 0.4 - 0.5 )\n",
            "\n",
            "summarised\n",
            "auroc\n",
            "0.73 ( 0.7 - 0.76 )\n",
            "auprc\n",
            "0.47 ( 0.42 - 0.52 )\n"
          ]
        }
      ],
      "source": [
        "#This bootstraps the hold out set 2000 fold to derive the 95% confidence intervals for each of the approaches:\n",
        "\n",
        "from functions.bootstrap import *\n",
        "\n",
        "print('last_value')\n",
        "score, ci_lower, ci_upper, scores = score_ci(y_test_last, predictions_last, score_fun=rc)\n",
        "print('auroc')\n",
        "print(round(score,2),'(',round(ci_lower,2),'-',round(ci_upper,2),')')\n",
        "score, ci_lower, ci_upper, scores = score_ci(y_test_last, predictions_last, score_fun=ap)\n",
        "print('auprc')\n",
        "print(round(score,2),'(',round(ci_lower,2),'-',round(ci_upper,2),')')\n",
        "print('')\n",
        "print('mean_value')\n",
        "score, ci_lower, ci_upper, scores = score_ci(y_test_mean, predictions_mean, score_fun=rc)\n",
        "print('auroc')\n",
        "print(round(score,2),'(',round(ci_lower,2),'-',round(ci_upper,2),')')\n",
        "score, ci_lower, ci_upper, scores = score_ci(y_test_mean, predictions_mean, score_fun=ap)\n",
        "print('auprc')\n",
        "print(round(score,2),'(',round(ci_lower,2),'-',round(ci_upper,2),')')\n",
        "print('')\n",
        "print('summarised')\n",
        "score, ci_lower, ci_upper, scores = score_ci(y_test, predictions, score_fun=rc)\n",
        "print('auroc')\n",
        "print(round(score,2),'(',round(ci_lower,2),'-',round(ci_upper,2),')')\n",
        "score, ci_lower, ci_upper, scores = score_ci(y_test, predictions, score_fun=ap)\n",
        "print('auprc')\n",
        "print(round(score,2),'(',round(ci_lower,2),'-',round(ci_upper,2),')')"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - Pytorch and Tensorflow",
      "language": "python",
      "name": "python38-azureml-pt-tf"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
